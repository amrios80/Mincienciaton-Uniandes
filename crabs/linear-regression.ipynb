{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjzzT5n_Fg3I"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/datascience-uniandes/linear-regression-tutorial/blob/master/crabs/linear-regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1weRDuPgFg3N"
      },
      "source": [
        "# Linear Regression\n",
        "\n",
        "MINE-4101: Applied Data Science  \n",
        "Univerisdad de los Andes  \n",
        "\n",
        "**Business context:** CrabsAlpes es una empresa líder en la industria pesquera que se especializa en la captura y distribución de cangrejos en la región de los Alpes. A medida que la demanda de cangrejos ha aumentado, también ha crecido la necesidad de entender con precisión las características y calidad de sus capturas. Parte de la calidad se relaciona con la edad del cangrejo, ya que puede influir en el sabor y textura de la carne. Sin embargo, determinar la edad exacta de un cangrejo solo a través de su apariencia es un reto. Por ello, CrabAlpes quiere desarrollar un modelo de regresión lineal que pueda estimar la edad de un cangrejo basándose en características físicas medibles como la longitud, el diámetro, el peso, entre otras. Con este modelo, la empresa espera mejorar la clasificación y venta de sus productos, garantizando a sus clientes un estándar de calidad y frescura uniforme.\n",
        "\n",
        "**Dataset:** Crab Age Prediction, source: [Kaggle](https://www.kaggle.com/datasets/sidhus/crab-age-prediction).\n",
        "\n",
        "**Data dictionary:**  \n",
        "- Sex (char): Sexo. Masculino, femenino o indeterminado.  \n",
        "- Length (numeric): Longitud.  \n",
        "- Diameter (numeric): Diámetro.  \n",
        "- Height (numeric): Altura.  \n",
        "- Weight (numeric): Peso.  \n",
        "- Shucked Weight (numeric): Peso descascarado.  \n",
        "- Viscera Weight (numeric): Peso de las vísceras.  \n",
        "- Shell Weight (numeric): Peso del caparazón.  \n",
        "- Age (numeric): Edad.\n",
        "\n",
        "Last update: September, 2023"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCH4SsNFFg3P"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from joblib import dump, load\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
        "\n",
        "import scipy.stats as stats"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zsq8U8ccFg3R"
      },
      "outputs": [],
      "source": [
        "pd.set_option(\"display.max_columns\", None)\n",
        "pd.set_option(\"display.max_rows\", 50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "tsJNgCoTFg3R"
      },
      "source": [
        "## 1. Carga de los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFgKL59UFg3S"
      },
      "outputs": [],
      "source": [
        "crabs_df = pd.read_csv(\"./data/CrabAgePrediction.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Y2zqoWQFg3S"
      },
      "outputs": [],
      "source": [
        "crabs_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2OhQdo5Fg3S"
      },
      "outputs": [],
      "source": [
        "crabs_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GC3VJG0Fg3T"
      },
      "outputs": [],
      "source": [
        "crabs_df.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "BGXSeo6iFg3T"
      },
      "source": [
        "## 2. Entendimiento y limpieza de los datos\n",
        "\n",
        "Para entrenar un modelo de regresión todas las variables de entrada (features) deben ser numéricas. Con ayuda de los expertos, se seleccionan las variables numéricas que se consideran más importantes para la estimación de la variable objetivo (target) `Age`. Para este caso se decide prescindir de la variable `Weight` dado que se considera que se puede realizar una estimación más precisa teniendo en cuenta los pesos individuales de sus partes.\n",
        "\n",
        "Adicionalmente, tanto las variables de entrada como la variable objetivo no deben contener valores vacíos. Se decide eliminar los registros que tengan valores vacíos en algunas de estas, dado que el experto recomienda no realizar ninguna imputación.\n",
        "\n",
        "<span style=\"color: red;\">Recuerde que la eliminación de registros debe ser considerada la última opción durante el proceso de limpieza de datos.</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C6Kd9abyFg3U"
      },
      "outputs": [],
      "source": [
        "features = [\"Length\", \"Diameter\", \"Height\", \"Shucked Weight\", \"Viscera Weight\", \"Shell Weight\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bySOD__oFg3U"
      },
      "outputs": [],
      "source": [
        "crabs_df[[\"Age\"]+features].isnull().sum() / crabs_df.shape[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLE9drE7Fg3U"
      },
      "outputs": [],
      "source": [
        "crabs_df = crabs_df.dropna(subset=[\"Age\"]+features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fEnq9KwJFg3V"
      },
      "outputs": [],
      "source": [
        "crabs_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sU9A_sPSFg3V"
      },
      "outputs": [],
      "source": [
        "crabs_df[[\"Age\"]+features].isnull().sum() / crabs_df.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RaLzs_PFg3V"
      },
      "source": [
        "### 2.1. Búsqueda de relaciones con la variable objetivo\n",
        "\n",
        "Si se logra visualizar o cuantificar altas correlaciones entre las variables de entrada y la variable objetivo, se podrán soportar las decisiones del experto con base en la evidencia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DTYE_COJFg3V"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(crabs_df.sample(frac=0.2), height=4, y_vars=\"Age\", x_vars=features, kind=\"scatter\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLnLswT3Fg3V"
      },
      "source": [
        "### 2.2. Búsqueda de relaciones entre las variables de entrada\n",
        "\n",
        "**Importante:** La regresión lineal asume que sus variables de entrada no se encuentran altamente correlacionados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwKKKX8TFg3V"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(crabs_df[features].corr(), cmap=\"Blues\", vmin=0, vmax=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHAK9yJMFg3V"
      },
      "source": [
        "Un buen punto de corte (empírico) para decidir si descartar una variable debido a su alta correlación con otra es ~$|0.8|$. Este análisis se retomará más adelante durante la comprobación de supuestos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "rkLTWo7-Fg3V"
      },
      "source": [
        "## 3. Prepración de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1z7kstQqFg3W"
      },
      "source": [
        "Por lo general, en el Machine Learning supervisado también suele ser común verificar si existen registros duplicados, particularmente para el conjunto de variables de entrada y variable objetivo. Mantener registros duplicados, aún sin considerarse un problema de calidad de los datos, ocasionará que durante el proceso de aprendizaje el algoritmo otorgue de forma errónea un peso mayor a estos registros duplicados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "44lokwKmFg3W"
      },
      "outputs": [],
      "source": [
        "total_rows = crabs_df.shape[0]\n",
        "total_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPrkvMZ-Fg3W"
      },
      "outputs": [],
      "source": [
        "crabs_df.loc[crabs_df.duplicated(subset=features, keep=False)].head(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXkrltJAFg3W"
      },
      "outputs": [],
      "source": [
        "duplicated_rows = crabs_df.loc[crabs_df.duplicated(subset=features, keep=False)].shape[0]\n",
        "duplicated_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZSUnSGWrFg3W"
      },
      "outputs": [],
      "source": [
        "print(f\"Duplicates: {(duplicated_rows/total_rows)*100:.4f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYLyvozzFg3W"
      },
      "outputs": [],
      "source": [
        "crabs_df.loc[crabs_df.duplicated(subset=features+[\"Age\"], keep=False)].tail(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HvKG0okFg3W"
      },
      "outputs": [],
      "source": [
        "duplicated_rows = crabs_df.loc[crabs_df.duplicated(subset=features+[\"Age\"], keep=False)].shape[0]\n",
        "duplicated_rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjSzQNGqFg3W"
      },
      "outputs": [],
      "source": [
        "print(f\"Duplicates: {(duplicated_rows/total_rows)*100:.4f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdSSOIP9Fg3W"
      },
      "source": [
        "Aquí hay dos escenarios a analizar:\n",
        "1. Existe un ~0.49% de registros con variables de entrada duplicadas, incluso con variable objetivo diferente. Una cantidad no muy preocupante pero que, en términos generales, requeriría de un proceso complementario de limpieza de datos para evitar confundir al modelo al momento de aprender la función de estimación.\n",
        "2. Al incluir la variable objetivo dentro del análisis de duplicados, se obtiene el 0.2% registros duplicados adicionales. Para un porcentaje mayor esto representaría potencialmente otro problema obligando al algoritmo de optimización a enfocarse más en aquellos registros duplicados en lugar de ponderar todos los registros por igual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cghhX5S-Fg3W"
      },
      "outputs": [],
      "source": [
        "crabs_df.drop_duplicates(subset=features, inplace=True)\n",
        "crabs_df.drop_duplicates(subset=features+[\"Age\"], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bk1_CQckFg3W"
      },
      "outputs": [],
      "source": [
        "crabs_df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "XSqQPoxlFg3W"
      },
      "source": [
        "## 4. Particionamiento del conjunto de datos en entrenamiento y prueba\n",
        "\n",
        "Se desea construir un modelo que se ajuste bien a los datos de entrenamiento, pero que además se comporte de forma similar con datos previamente desconocidos.\n",
        "\n",
        "Metodológicamente, una práctica común para validar esto es separando el conjunto de datos etiquetado en dos partes: entrenamiento y prueba. La proporción reservada para probar el modelo es definida por el analista, pero un valor común es 30%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qg04Q2sOFg3W"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(crabs_df[features], crabs_df[\"Age\"], test_size=0.3, random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcHrgwHXFg3W"
      },
      "outputs": [],
      "source": [
        "X_train.shape, y_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUIVfVF_Fg3W"
      },
      "outputs": [],
      "source": [
        "X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "-PHTcLaxFg3W"
      },
      "source": [
        "## 5. Entrenamiento de un primer modelo de regresión lineal\n",
        "\n",
        "Se deice que la regresión es lineal dado que se asume una relación lineal entre las variables de entrada (features) y la variable objetivo (target).\n",
        "\n",
        "En Scikit-Learn existen varias formas de implementar el algoritmo de regresión lieal, pero dado que el objetivo de esta practica esta enfocado en el análisis del modelo resultante y no tanto del algoritmo o del proceso de entrenamiento, se utilizará la implementación más sencilla dada por la clase LinearRegression."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4C4MAUSFg3X"
      },
      "outputs": [],
      "source": [
        "regression = LinearRegression()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSx_zHLLFg3X"
      },
      "outputs": [],
      "source": [
        "regression.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVH82uS-Fg3b"
      },
      "source": [
        "### 4.1. Interpretación de los coeficientes y del intercepto\n",
        "\n",
        "Los coeficientes de la regresión brindan una intuición del impacto o la fuerza de una variable de entrada en la predicción/estimación de la variable objetivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bih2r5wFg3b"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({\"columns\": features, \"coef\": regression.coef_})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRmh2MjeFg3b"
      },
      "outputs": [],
      "source": [
        "regression.intercept_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNw1O8QIFg3b"
      },
      "outputs": [],
      "source": [
        "f, axs = plt.subplots(1, len(features), sharey=True, figsize=(20, 4))\n",
        "\n",
        "for i in range(len(features)):\n",
        "    col = features[i]\n",
        "    x = X_train[col]\n",
        "    m = regression.coef_[i]\n",
        "    b = regression.intercept_\n",
        "\n",
        "    axs[i].plot(x, y_train, \"o\", alpha=0.1)\n",
        "    axs[i].plot(x, x * m + b)\n",
        "    axs[i].set_title(col)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFb_sv4VFg3b"
      },
      "source": [
        "Recuerde que el modelo de regresión lineal para este caso particular está dado de la forma\n",
        "\n",
        "$$ y = {\\beta_{0} + \\beta_{1}x_{1} + \\beta_{2}x_{2} + \\beta_{3}x_{3} + \\beta_{4}x_{4} + \\beta_{5}x_{5}} $$\n",
        "\n",
        "siendo $\\beta_{0}$ el intercepto (bias) y $\\beta_{1}$, $\\beta_{2}$, $\\beta_{3}$, $\\beta_{4}$ y $\\beta_{5}$ los coeficientes o parámetros correspondientes a las variables de entrada en el mismo orden.\n",
        "\n",
        "Tenga en cuenta que:\n",
        "1) El signo del coeficiente representa la dirección de la relación entre la variable de entrada correspondiente y la variable objetivo. Signos positivos implican que si el valor de la variable de entada aumenta, el valor de la variable objetivo también aumentará, mientras que signos negativos indican que si el valor de la variable de entrada aumenta, el valor de la variable objetivo disminuirá.\n",
        "2) El valor del coeficiente cuantifica la magnitud de la relación, implicando que un aumento o disminución (dependiendo del signo del coeficiente) en una unidad de la variable de entrada representará un cambio equivalente al valor del coeficiente en la variable objetivo, asumiendo que los valores de las demás variables de entrada permanezcan constantes.\n",
        "\n",
        "**Ejemplo:**\n",
        "\n",
        "Haciendo énfasis en `valence`, se sabe que cada cambio unitario en esta variable tendrá un impacto porcentual equivalente a ~11.4% en la variable objetivo, asumiendo que los valores de las demás variables permanecen constantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKWW7eOxFg3b"
      },
      "outputs": [],
      "source": [
        "# Dado que `Diameter` se encuentra en el rango de 0 a 1, se simula un cambio de 0.1 múltiples veces para un mismo registro\n",
        "# Siendo el incremento de apenas 1/10 de unidad, se espera un cambio en la estimación de la variable objetivo de ~0.57%\n",
        "df = pd.concat([crabs_df[features].iloc[0:1]] * 5).reset_index()\n",
        "df[\"Diameter\"] = df[\"Diameter\"] + (df.index / 10)\n",
        "df[\"prediction\"] = regression.predict(df[features])\n",
        "df[\"% change\"] = df[\"prediction\"].diff()\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqk7JtaEFg3b"
      },
      "source": [
        "Aún cuando el cambio en la variable objetivo es el esperado, note que las variables de entrada no se encuentran en la misma escala, rangos o grados de magnitud. Debido a esto, las magnitudes o valores de los coeficientes no son directamente comparables entre sí, es decir, no es posible decir por ejemplo que `Diameter` tiene un impacto mayor que `Shell Weight` en la estimación de la edad de un cangrejo. Aunque si se puede decir que `Length` tiene un impacto negativo en la estimación.\n",
        "\n",
        "Por otro lado, el intercepto puede ser útil para determinar un valor de base en la estimación, en este caso una edad mínima bajo el supuesto de que pudiera existir un cangrejo con todas sus variables de entrada iguales a cero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVNRdNFzFg3b"
      },
      "source": [
        "### 4.2. Validación (evaluación) del modelo\n",
        "\n",
        "La forma más básica para saber que tan bien se comporta el modelo es midiendo que tanto se alejan las estimaciones o predicciones del mismo respecto a la variable objetivo real. Esta medición se puede hacer tanto para el conjunto de datos de entrenamiento como para el de prueba."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "ZuTe12PAFg3b"
      },
      "source": [
        "**Mean Absolute Error (MAE)**\n",
        "\n",
        "$$ MAE = {1 \\over n}{\\sum_{i=1}^n {|y_{i} - y_{i}'|} } $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PmR432MMFg3b"
      },
      "outputs": [],
      "source": [
        "print(\"Train:\", mean_absolute_error(y_train, regression.predict(X_train)))\n",
        "print(\"Test:\", mean_absolute_error(y_test, regression.predict(X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xgvh7LePFg3b"
      },
      "source": [
        "**Root Mean Squeared Error (RMSE)**\n",
        "\n",
        "$$ RMSE = {1 \\over n}{\\sum_{i=1}^n {(y_{i} - y_{i}')^2} } $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aT1MD3PhFg3b"
      },
      "outputs": [],
      "source": [
        "print(\"Train:\", np.sqrt(mean_squared_error(y_train, regression.predict(X_train))))\n",
        "print(\"Test:\", np.sqrt(mean_squared_error(y_test, regression.predict(X_test))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMBxrL4SFg3b"
      },
      "source": [
        "**Análisis del error**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZpgzJq9Fg3b"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 3))\n",
        "sns.boxplot(x=y_test, showmeans=True, orient=\"h\")\n",
        "plt.title(\"Valor real de $\\t{Age}$ en el conjunto de prueba\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jIM7bmDAFg3c"
      },
      "outputs": [],
      "source": [
        "y_test.describe(percentiles=[0.25, 0.5, 0.75, 0.99])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xEn96bamFg3c"
      },
      "source": [
        "Aún cuando `Age` se mueve en el rango de 3 a 27, la mayoría de sus posibles valores se encuentran entre 5 y 15. Tener esto claro es importante para determinar que tan grande o que tan bajo es el error promedio respecto a la variable objetivo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wz70oM1vFg3c"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 3))\n",
        "sns.boxplot(x=abs(y_test - regression.predict(X_test)), showmeans=True, orient=\"h\")\n",
        "plt.title(\"|Valor real - Valor estimado| de $\\t{Age}$\")\n",
        "plt.xlabel(\"Error\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "74wWEVKpFg3c"
      },
      "outputs": [],
      "source": [
        "abs(y_test-regression.predict(X_test)).describe(percentiles=[0.25, 0.5, 0.75, 0.95, 0.99])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7laH4ENFg3c"
      },
      "source": [
        "Se podría decir que los resultados de este primer modelo son aceptables dado que:\n",
        "1) Las métricas de error para el dataset de entrenamiento y prueba son muy similares. No se evidencian problemas de sobreajuste (overfitting).\n",
        "2) Para el conjunto de prueba los valores de la variable objetivo están centrados en $9.8 \\pm 3.1$, mientras que el 75% de los errores de estimación del modelo se encuentran por debajo de 2.1, muy por debajo de una desviación estándar.\n",
        "\n",
        "Un análisis del error más profundo implicaría, por ejemplo, identificar si el problema mayor se encuentra en la subestimación o la sobreestimación de la edad, así como ganar mayor intuición de cuales son los casos particulares en los que el modelo se equivoca más."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "bCfDNiy-Fg3c"
      },
      "source": [
        "## 6. Entrenamiento de un segundo modelo aplicando normalización\n",
        "\n",
        "Scikit-Learn permite integrar el proceso de normalización de features dentro de los procesos de entrenamiento y predicción de los modelos mediante el uso de Pipelines. Un Pipeline permite ejecutar de forma secuencial un conjunto de transformaciones de datos, selección de variables, entre otros, seguido del paso de entrenamiento o predicción.\n",
        "\n",
        "La documentación oficial de Pipelines se puede encontrar aquí: https://scikit-learn.org/stable/modules/compose.html."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koZZllIIFg3c"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"model\", LinearRegression())\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GAH8fbhFg3c"
      },
      "outputs": [],
      "source": [
        "pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8R6S5-NFg3d"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({\"columns\": features, \"coef\": pipeline[\"model\"].coef_})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9Wt5ie1Fg3d"
      },
      "outputs": [],
      "source": [
        "pipeline[\"model\"].intercept_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDR0GyVRFg3d"
      },
      "outputs": [],
      "source": [
        "y_train.mean(), y_test.mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BjHjFeMYFg3d"
      },
      "source": [
        "Aunque tras la transformación de las variables de entrada se pierde un poco de interpretabilidad de los datos, los coeficientes de la regresión ahora son directamente comparables, pudiendo decir que la variable de entrada que mayor tiene impacto en la variable objetivo es `Shell Weight`, muy por encima de `Diameter` que es la siguiente en magnitud. No se debe olvidar los coeficientes negativos, particularmente el correspondiente a la variable `Shucked Weight`, el cuál tiene una magnitud alta muy similar a `Shell Weight` en términos de valor absoluto.\n",
        "\n",
        "La forma de entender el intercepto también cambia un poco. Al haber normalizado las variables de entrada, particularmente al haber centrado cada variable en cero removiendo su valor promedio, el valor del intercepto indica cual sería el valor de edad para un cangrejo promedio. Esto tiene sentido dado que corresponde con el valor promedio real (aproximado) de `Age` tanto para el conjunto de entrenamiento como para el de prueba."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxf8kHj4Fg3d"
      },
      "outputs": [],
      "source": [
        "print(\"MAE:\")\n",
        "print(\"Train:\", mean_absolute_error(y_train, pipeline.predict(X_train)))\n",
        "print(\"Test:\", mean_absolute_error(y_test, pipeline.predict(X_test)))\n",
        "print(\"\\nRMSE:\")\n",
        "print(\"Train:\", np.sqrt(mean_squared_error(y_train, pipeline.predict(X_train))))\n",
        "print(\"Test:\", np.sqrt(mean_squared_error(y_test, pipeline.predict(X_test))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqsjVVlGFg3d"
      },
      "source": [
        "<span style=\"color: red;\">Recuerde que la normalización de datos no siempre implica mejores métricas de error pero si garantiza un mejor proceso de entrenamiento y, dependiendo de la técnica de normalización utilizada, menor sensibilidad a valores atípicos.</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "3OyYasEzFg3d"
      },
      "source": [
        "## 7. Validación de supuestos de la regresión\n",
        "\n",
        "La construcción de un buen modelo de Machine Learning va más allá de solamente minimizar las métricas de error. El modelo de regresión lineal, desde una perspectiva clásica, debería además cumplir con los siguientes supuestos:\n",
        "\n",
        "*Se volverán a revisar algunos aspectos que se habían descubierto en la etapa de entendimiento de los datos.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "nrPlwNm8Fg3e"
      },
      "source": [
        "### 7.1. Colinealidad\n",
        "\n",
        "Es necesario que las variables utilizadas no tengan (o tengan muy baja) colinealidad (correlación)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hsLpExxFg3e"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(X_train.corr(), cmap=\"Blues\", vmin=0, vmax=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQfXxWLEFg3e"
      },
      "outputs": [],
      "source": [
        "X_train.corr()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkoxGy6pFg3e"
      },
      "source": [
        "En este caso particular, para evitar eliminar un importante número de variables, se opta por eliminar aquellas cuyo valor de correlación es superior al 90%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a44kSxCeFg3e"
      },
      "outputs": [],
      "source": [
        "features2 = [\"Length\", \"Height\", \"Shucked Weight\", \"Shell Weight\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQYVwX1UFg3f"
      },
      "outputs": [],
      "source": [
        "X_train[features2].corr()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zNc-xBHuFg3f"
      },
      "outputs": [],
      "source": [
        "pipeline.fit(X_train[features2], y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCcGmrq1Fg3f"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({\"columns\": features2, \"coef\": pipeline[\"model\"].coef_})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ocTYXGy_Fg3f"
      },
      "outputs": [],
      "source": [
        "pipeline[\"model\"].intercept_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xejzuhC4Fg3f"
      },
      "outputs": [],
      "source": [
        "print(\"MAE:\")\n",
        "print(\"Train:\", mean_absolute_error(y_train, pipeline.predict(X_train[features2])))\n",
        "print(\"Test:\", mean_absolute_error(y_test, pipeline.predict(X_test[features2])))\n",
        "print(\"\\nRMSE:\")\n",
        "print(\"Train:\", np.sqrt(mean_squared_error(y_train, pipeline.predict(X_train[features2]))))\n",
        "print(\"Test:\", np.sqrt(mean_squared_error(y_test, pipeline.predict(X_test[features2]))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzAgrSxpFg3f"
      },
      "source": [
        "Hay algunos argumentos para decir que este nuevo modelo podría considerarse mejor que los anteriores:\n",
        "1. Con el uso de menos variables de entrada (menor complejidad del modelo) se logra obtener unas métricas de error muy similares.\n",
        "2. Se evidencia un mejor balance entre coeficientes de `Length` y `Height`, sin embargo, aún se observa coeficientes altos para `Shucked Weight` y `Shell Weight`. Idealmente, los coeficientes deberían estar lo más balanceados posible para evitar que el modelo sesgue sus estimaciones con base en solo unas pocas variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "2qBGZnxSFg3f"
      },
      "source": [
        "### 7.2. Linealidad\n",
        "\n",
        "Es necesario que la relación entre cada variable de entrada y la varable objetivo sea lineal.\n",
        "\n",
        "![lineal.png](attachment:lineal.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yCVv6dXiFg3f"
      },
      "outputs": [],
      "source": [
        "sns.pairplot(pd.concat([X_train, y_train], axis=1), height=4, y_vars=\"Age\", x_vars=features2, kind=\"scatter\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6crTvkjFg3f"
      },
      "source": [
        "¿Es posible que `Shucked Weight` y `Shell Weight` tengan una relación no lineal?\n",
        "\n",
        "La forma más común de comprobarlo es agregar una transformación polinomial (PolynomialFeatures) de algún grado integrada al Pipeline. Tenga en cuenta que la transformación se aplicará a todas las variables de entrada y será labor del algoritmo de regresión determinar cuáles son las más relevantes para la estimación.\n",
        "\n",
        "La documentación oficial de PolynomialFeatures se puede encontrar aquí: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNFJgNgaFg3f"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline(\n",
        "    [\n",
        "        (\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"model\", LinearRegression())\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56yyjB6BFg3f"
      },
      "outputs": [],
      "source": [
        "pipeline.fit(X_train[features2], y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z8An1I-LFg3f"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({\"columns\": pipeline[\"poly\"].get_feature_names_out(), \"coef\": pipeline[\"model\"].coef_})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNpjK5GPFg3f"
      },
      "source": [
        "<span style=\"color: red;\">Note que PolynomialFeatures no solo transforma las variables de entrada aplicando el grado deseado, también conserva las variables originales e incluye interacciones (multiplicación) entre estas. Esto hace que la interpretación de los coeficientes se vuelva más dificil.</span>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U6gNOLRuFg3f"
      },
      "outputs": [],
      "source": [
        "print(\"MAE:\")\n",
        "print(\"Train:\", mean_absolute_error(y_train, pipeline.predict(X_train[features2])))\n",
        "print(\"Test:\", mean_absolute_error(y_test, pipeline.predict(X_test[features2])))\n",
        "print(\"\\nRMSE:\")\n",
        "print(\"Train:\", np.sqrt(mean_squared_error(y_train, pipeline.predict(X_train[features2]))))\n",
        "print(\"Test:\", np.sqrt(mean_squared_error(y_test, pipeline.predict(X_test[features2]))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8GHQLjeFg3f"
      },
      "source": [
        "Nuevamente, aplicar este tipo de ajustes no asegura obtener un modelo con un menor error. Algunas razones por las cuáles el RMSE en el dataset de prueba aumento en lugar de disminuir pueden ser:\n",
        "\n",
        "1. La existencia de algunos valores atípicos solamente en el dataset de test los cuales se agravaron al aplicar la transformación polinomial.\n",
        "2. Tal como se videncia en las gráficas anteriores, si bien la relación con la variable objetivo puede no ser lineal, lo más probable es que tampoco sea polinómica sino más bien logaritmica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "rSAAroUZFg3g"
      },
      "source": [
        "### 7.3. Normalidad de los errores\n",
        "\n",
        "Los errores deben tener una distribución normal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4bh45GPFg3g"
      },
      "source": [
        "![dist.png](attachment:dist.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHMHjmf8Fg3g"
      },
      "source": [
        "![dist2.png](attachment:dist2.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91DvQ6ZSFg3g"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline(\n",
        "    [\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"model\", LinearRegression())\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtxRt9iEFg3g"
      },
      "outputs": [],
      "source": [
        "pipeline.fit(X_train[features2], y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KqnfR7nCFg3g"
      },
      "outputs": [],
      "source": [
        "errors = (pipeline.predict(X_train[features2])-y_train).values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lo_vx3MTFg3g"
      },
      "source": [
        "Valores negativos indican subestimación mientras que valores positivos indican sobreestimación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PxA6HVPkFg3g"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Dispersión\n",
        "sns.scatterplot(x=pipeline.predict(X_train[features2]), y=errors, alpha=0.1, ax=axes[0])\n",
        "\n",
        "# q-q plot\n",
        "_ = stats.probplot(errors, dist=\"norm\", plot=axes[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JmM3iUKFg3g"
      },
      "source": [
        "Una estrategia para mejorar este escenario es eliminar los registros cuyo valor de variable objetivo pueda considerarse un valor atípico."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7AnTr4nFg3g"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 3))\n",
        "sns.boxplot(x=y_train, showmeans=True, orient=\"h\")\n",
        "plt.title(\"Valor real de $\\t{Age}$ en el conjunto de entrenamiento\")\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89JEyWerFg3g"
      },
      "source": [
        "Para determinar los valores atípicos a remover se puede aplicar la regla $$outlier > Q3 + 1.5*IQR$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d86ccl6vFg3g"
      },
      "outputs": [],
      "source": [
        "q1 = y_train.quantile(0.25)\n",
        "q3 = y_train.quantile(0.75)\n",
        "iqr = q3-q1\n",
        "threshold = q3+1.5*iqr\n",
        "threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cSeIcBLFg3g"
      },
      "outputs": [],
      "source": [
        "y_train = y_train.loc[y_train <= threshold]\n",
        "X_train = X_train.loc[y_train.index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJYtxTI6Fg3g"
      },
      "outputs": [],
      "source": [
        "y_test = y_test.loc[y_test <= threshold]\n",
        "X_test = X_test.loc[y_test.index]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcizE4iPFg3g"
      },
      "outputs": [],
      "source": [
        "pipeline.fit(X_train[features2], y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a-06gfAnFg3h"
      },
      "outputs": [],
      "source": [
        "pd.DataFrame({\"columns\": features2, \"coef\": pipeline[\"model\"].coef_})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otlZJOwpFg3h"
      },
      "outputs": [],
      "source": [
        "print(\"MAE:\")\n",
        "print(\"Train:\", mean_absolute_error(y_train, pipeline.predict(X_train[features2])))\n",
        "print(\"Test:\", mean_absolute_error(y_test, pipeline.predict(X_test[features2])))\n",
        "print(\"\\nRMSE:\")\n",
        "print(\"Train:\", np.sqrt(mean_squared_error(y_train, pipeline.predict(X_train[features2]))))\n",
        "print(\"Test:\", np.sqrt(mean_squared_error(y_test, pipeline.predict(X_test[features2]))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwKb0Bh8Fg3h"
      },
      "outputs": [],
      "source": [
        "errors = (pipeline.predict(X_train[features2])-y_train).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ykc4PeidFg3h"
      },
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
        "\n",
        "# Dispersión\n",
        "sns.scatterplot(x=pipeline.predict(X_train[features2]), y=errors, alpha=0.1, ax=axes[0])\n",
        "\n",
        "# q-q plot\n",
        "_ = stats.probplot(errors, dist=\"norm\", plot=axes[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-Hp6ZgRFg3h"
      },
      "source": [
        "Se siguen teniendo mejoras en las métricas de error y se resuelve el problema de no normalidad de los errores.\n",
        "\n",
        "<span style=\"color: red;\">Desde el punto de vista de la estadística clásica esto está bien, pero también se debe preguntar: Si las canciones removidas son atípicas pero reales, es decir no obedecen a un problema en los datos, ¿qué decisión debería tomar el modelo en estos casos? ¿Cómo construir un modelo que sea más robusto a valores atípicos?</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "2FPS2opTFg3h"
      },
      "source": [
        "### 7.4 Varianza constante (Homocedasticidad)\n",
        "\n",
        "La varianza en los errores debe mantenerse constante a medida que varia la variable objetivo.\n",
        "\n",
        "![variance.png](attachment:variance.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0Z-EGtjFg3h"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x = pipeline.predict(X_train[features2]), y=errors, alpha=0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdIi3c-dFg3h"
      },
      "source": [
        "Este problema podría resolverse aplicando nuevamente transformaciones no lineales sobre las variables de entrada. Por otro lado, también puede indicar que hacen falta variables de entrada que ayuden a representar apropiadamente la variable objetivo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "tags": [],
        "id": "M3T-bnsjFg3h"
      },
      "source": [
        "## 8. Persistencia del modelo\n",
        "\n",
        "Una vez que el modelo está listo, ¿cómo ponerlo en producción para que realice estimaciones para datos futuos?\n",
        "\n",
        "Se debe empezar por persistir el modelo a un archivo binario para que posteriormente pueda ser reutilizado desde cualquier script o servicio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Z7kWaFTFg3h"
      },
      "outputs": [],
      "source": [
        "filename = \"model.joblib\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "29fCADkuFg3h"
      },
      "outputs": [],
      "source": [
        "dump(pipeline, filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YCeCtWsdFg3h"
      },
      "outputs": [],
      "source": [
        "pipeline_loaded = load(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqddD4wYFg3h"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "toc-autonumbering": false,
    "toc-showcode": true,
    "toc-showmarkdowntxt": false,
    "toc-showtags": true,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}